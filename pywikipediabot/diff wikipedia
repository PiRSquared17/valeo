===============================================
cvs diff -r 1.603 -r 1.602 -- wikipedia.py (in directory C:\pywikipedia-cvs\pywikipedia\)
Index: wikipedia.py
===================================================================
RCS file: /cvsroot/pywikipediabot/pywikipedia/wikipedia.py,v
retrieving revision 1.603
retrieving revision 1.602
diff -r1.603 -r1.602
1c1
< # -*- coding: utf-8  -*-
---
> ?# -*- coding: utf-8  -*-
47,62c47,50
< 
<     Special pages:
<         Dinamic pages: 
<             allpages(): Special:Allpages
<             newpages(): Special:Newpages
<             longpages(): Special:Longpages
<             shortpages(): Special:Shortpages
<             categories(): Special:Categories
< 
<         Cached pages:
<             deadendpages(): Special:Deadendpages
<             ancientpages(): Special:Ancientpages
<             lonelypages(): Special:Lonelypages
<             uncategorizedcategories(): Special:Uncategorizedcategories
<             uncategorizedpages(): Special:Uncategorizedpages
<             unusedcategories(): Special:Unusuedcategories
---
>     allpages(): Load allpages special page
>     newpages(): Load newpages special page
>     longpages(): Load longpages special page
>     ...
102c90
< __version__ = '$Id: wikipedia.py,v 1.602 2005/10/05 23:26:36 a_engels Exp $'
---
> __version__ = '$Id: wikipedia.py,v 1.601 2005/10/04 20:50:20 leogregianin Exp $'
1916,2061d1903
<             
<     def shortpages(self, number = 10, repeat = False):
<         throttle = True
<         seen = set()
<         while True:
<             path = self.shortpages_address()
<             get_throttle()
<             html = self.getUrl(path)
<             entryR = re.compile('<li><a href=".+?" title="(?P<title>.+?)">.+?</a> \((?P<length>\d+)(.+?)\)</li>')
<             for m in entryR.finditer(html):
<                 title = m.group('title')
<                 length = int(m.group('length'))
<                    
<                 if title not in seen:
<                     seen.add(title)
<                     page = Page(self, title)
<                     yield page, length
<             if not repeat:
<                 break
< 
<     def categories(self, number = 10, repeat = False):
<         throttle = True
<         seen = set()
<         while True:
<             path = self.categories_address()
<             get_throttle()
<             html = self.getUrl(path)
<             entryR = re.compile('<li><a href=".+?" title="(?P<title>.+?)">.+?</a></li>')
<             for m in entryR.finditer(html):
<                 title = m.group('title')
<                                    
<                 if title not in seen:
<                     seen.add(title)
<                     page = Page(self, title)
<                     yield page
<             if not repeat:
<                 break
< 
<     def deadendpages(self, number = 10, repeat = False):
<         throttle = True
<         seen = set()
<         while True:
<             path = self.deadendpages_address()
<             get_throttle()
<             html = self.getUrl(path)
<             entryR = re.compile('<li><a href=".+?" title="(?P<title>.+?)">.+?</a></li>')
<             for m in entryR.finditer(html):
<                 title = m.group('title')
<                                    
<                 if title not in seen:
<                     seen.add(title)
<                     page = Page(self, title)
<                     yield page
<             if not repeat:
<                 break
< 
<     def ancientpages(self, number = 10, repeat = False):
<         throttle = True
<         seen = set()
<         while True:
<             path = self.ancientpages_address()
<             get_throttle()
<             html = self.getUrl(path)
<             entryR = re.compile('<li><a href=".+?" title="(?P<title>.+?)">.+?</a> (?P<date>.+?)</li>')
<             for m in entryR.finditer(html):
<                 title = m.group('title')
<                 date = m.group('date')
<                                                   
<                 if title not in seen:
<                     seen.add(title)
<                     page = Page(self, title)
<                     yield page, date
<             if not repeat:
<                 break
<     
<     def lonelypages(self, number = 10, repeat = False):
<         throttle = True
<         seen = set()
<         while True:
<             path = self.lonelypages_address()
<             get_throttle()
<             html = self.getUrl(path)
<             entryR = re.compile('<li><a href=".+?" title="(?P<title>.+?)">.+?</a></li>')
<             for m in entryR.finditer(html):
<                 title = m.group('title')
<                                    
<                 if title not in seen:
<                     seen.add(title)
<                     page = Page(self, title)
<                     yield page
<             if not repeat:
<                 break
< 
<     def uncategorizedcategories(self, number = 10, repeat = False):
<         throttle = True
<         seen = set()
<         while True:
<             path = self.uncategorizedcategories_address()
<             get_throttle()
<             html = self.getUrl(path)
<             entryR = re.compile('<li><a href=".+?" title="(?P<title>.+?)">.+?</a></li>')
<             for m in entryR.finditer(html):
<                 title = m.group('title')
<                                    
<                 if title not in seen:
<                     seen.add(title)
<                     page = Page(self, title)
<                     yield page
<             if not repeat:
<                 break
< 
<     def uncategorizedpages(self, number = 10, repeat = False):
<         throttle = True
<         seen = set()
<         while True:
<             path = self.uncategorizedpages_address()
<             get_throttle()
<             html = self.getUrl(path)
<             entryR = re.compile('<li><a href=".+?" title="(?P<title>.+?)">.+?</a></li>')
<             for m in entryR.finditer(html):
<                 title = m.group('title')
<                                    
<                 if title not in seen:
<                     seen.add(title)
<                     page = Page(self, title)
<                     yield page
<             if not repeat:
<                 break
< 
<     def unusedcategories(self, number = 10, repeat = False):
<         throttle = True
<         seen = set()
<         while True:
<             path = self.unusedcategories_address()
<             get_throttle()
<             html = self.getUrl(path)
<             entryR = re.compile('<li><a href=".+?" title="(?P<title>.+?)">.+?</a></li>')
<             for m in entryR.finditer(html):
<                 title = m.group('title')
<                                    
<                 if title not in seen:
<                     seen.add(title)
<                     page = Page(self, title)
<                     yield page
<             if not repeat:
<                 break
2202,2225d2043
<     def shortpages_address(self, n=500):
<         return self.family.shortpages_address(self.lang, n)
< 
<     def categories_address(self, n=500):
<         return self.family.categories_address(self.lang, n)
< 
<     def deadendpages_address(self, n=500):
<         return self.family.deadendpages_address(self.lang, n)
< 
<     def ancientpages_address(self, n=500):
<         return self.family.ancientpages_address(self.lang, n)
< 
<     def lonelypages_address(self, n=500):
<         return self.family.lonelypages_address(self.lang, n)
< 
<     def uncategorizedcategories_address(self, n=500):
<         return self.family.uncategorizedcategories_address(self.lang, n)
< 
<     def uncategorizedpages_address(self, n=500):
<         return self.family.uncategorizedpages_address(self.lang, n)
< 
<     def unusedcategories_address(self, n=500):
<         return self.family.unusedcategories_address(self.lang, n)
< 

cvs diff -r 1.108 -r 1.109 -- family.py (in directory C:\pywikipedia-cvs\pywikipedia\)
Index: family.py
===================================================================
RCS file: /cvsroot/pywikipediabot/pywikipedia/family.py,v
retrieving revision 1.108
retrieving revision 1.109
diff -r1.108 -r1.109
821a822,845
>     def shortpages_address(self, code, limit=500):
>         return "%s?title=%s:Shortpages&limit=%d" % (self.path(code), self.special_namespace_url(code), limit)
> 
>     def categories_address(self, code, limit=500):
>         return "%s?title=%s:Categories&limit=%d" % (self.path(code), self.special_namespace_url(code), limit)
> 
>     def deadendpages_address(self, code, limit=500):
>         return "%s?title=%s:Deadendpages&limit=%d" % (self.path(code), self.special_namespace_url(code), limit)
> 
>     def ancientpages_address(self, code, limit=500):
>         return "%s?title=%s:Ancientpages&limit=%d" % (self.path(code), self.special_namespace_url(code), limit)
> 
>     def lonelypages_address(self, code, limit=500):
>         return "%s?title=%s:Lonelypages&limit=%d" % (self.path(code), self.special_namespace_url(code), limit)
> 
>     def uncategorizedcategories_address(self, code, limit=500):
>         return "%s?title=%s:Uncategorizedcategories&limit=%d" % (self.path(code), self.special_namespace_url(code), limit)
>     
>     def uncategorizedpages_address(self, code, limit=500):
>         return "%s?title=%s:Uncategorizedpages&limit=%d" % (self.path(code), self.special_namespace_url(code), limit)
>     
>     def unusedcategories_address(self, code, limit=500):
>         return "%s?title=%s:Unusedcategories&limit=%d" % (self.path(code), self.special_namespace_url(code), limit)
> 